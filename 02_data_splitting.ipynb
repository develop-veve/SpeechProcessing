{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315f1d0a-2a20-43c2-b2e7-431501f9a9b3",
   "metadata": {},
   "source": [
    "# 02_data_splitting.ipynb（データ分割）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a63df5-09cc-4f5f-9823-ef3487082f35",
   "metadata": {},
   "source": [
    "### CSVファイルで保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "804781cd-5a11-4443-b7c5-d36d64ae9e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 音声特徴量をCSVとして保存しました: ./data\\features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ 保存先のディレクトリ\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "# ✅ 例として取得した音声特徴量（MFCC）と追加特徴量\n",
    "mfccs = np.random.rand(32, 13)  # 仮のMFCCデータ（32フレーム × 13次元）\n",
    "zcr = np.random.rand(32)  # ゼロ交差率\n",
    "centroid = np.random.rand(32)  # スペクトルセントロイド\n",
    "rms = np.random.rand(32)  # RMSエネルギー\n",
    "bandwidth = np.random.rand(32)  # スペクトルバンド幅\n",
    "\n",
    "# ✅ 特徴量データをDataFrameに格納（各行が1フレームに対応）\n",
    "feature_data = {\n",
    "    f\"MFCC{i+1}\": mfccs[:, i] for i in range(13)\n",
    "}\n",
    "feature_data[\"Zero_Crossing_Rate\"] = zcr\n",
    "feature_data[\"Spectral_Centroid\"] = centroid\n",
    "feature_data[\"RMS_Energy\"] = rms\n",
    "feature_data[\"Spectral_Bandwidth\"] = bandwidth\n",
    "\n",
    "# ✅ Pandas DataFrame に変換\n",
    "df = pd.DataFrame(feature_data)\n",
    "\n",
    "# ✅ CSVファイルとして保存\n",
    "csv_path = os.path.join(DATA_DIR, \"features.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 音声特徴量をCSVとして保存しました: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84918fe-8577-4ece-a2c1-036bd88a2f69",
   "metadata": {},
   "source": [
    "### CSV の保存データ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7acc800-5865-46c3-a458-b0bc6e258fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MFCC1     MFCC2     MFCC3     MFCC4     MFCC5     MFCC6     MFCC7  \\\n",
      "0  0.633518  0.168160  0.129056  0.080153  0.056238  0.923912  0.560058   \n",
      "1  0.005679  0.144129  0.055339  0.275091  0.353391  0.538304  0.330699   \n",
      "2  0.947128  0.659851  0.349774  0.612914  0.227628  0.059295  0.155140   \n",
      "3  0.119872  0.734340  0.309336  0.275991  0.517493  0.280081  0.888197   \n",
      "4  0.353305  0.185258  0.060374  0.652949  0.037002  0.745589  0.515441   \n",
      "\n",
      "      MFCC8     MFCC9    MFCC10    MFCC11    MFCC12    MFCC13  \\\n",
      "0  0.481837  0.324598  0.575755  0.807999  0.344541  0.984036   \n",
      "1  0.043408  0.713098  0.827738  0.701008  0.535437  0.069860   \n",
      "2  0.869220  0.154782  0.014640  0.492886  0.188924  0.329353   \n",
      "3  0.598496  0.553367  0.678009  0.880743  0.020144  0.868353   \n",
      "4  0.533350  0.733237  0.901828  0.207934  0.557173  0.198347   \n",
      "\n",
      "   Zero_Crossing_Rate  Spectral_Centroid  RMS_Energy  Spectral_Bandwidth  \n",
      "0            0.618272           0.513961    0.564364            0.681241  \n",
      "1            0.113218           0.357176    0.370149            0.575866  \n",
      "2            0.288177           0.743159    0.437104            0.658990  \n",
      "3            0.114200           0.654770    0.976185            0.289175  \n",
      "4            0.356616           0.573621    0.031847            0.779151  \n"
     ]
    }
   ],
   "source": [
    "df_loaded = pd.read_csv(csv_path)\n",
    "print(df_loaded.head())  # データの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ee6f5-82e2-48bb-beb2-90d9f5f8a91a",
   "metadata": {},
   "source": [
    "### 特徴量とラベルを .npyで保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1a44ae7-1e92-42e4-837b-10c3b4b26b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ yes フォルダ内の 4044 ファイルを処理中...\n",
      "  ├─ 4040 / 4044 ファイル処理中 ・・・・ \n",
      "✅ no フォルダ内の 3941 ファイルを処理中...\n",
      "  ├─ 3940 / 3941 ファイル処理中 ・・ ・ \n",
      "✅ up フォルダ内の 3723 ファイルを処理中...\n",
      "  ├─ 3720 / 3723 ファイル処理中 ・・・・ \n",
      "✅ down フォルダ内の 3917 ファイルを処理中...\n",
      "  ├─ 3910 / 3917 ファイル処理中 ・・・  \n",
      "✅ left フォルダ内の 3801 ファイルを処理中...\n",
      "  ├─ 3800 / 3801 ファイル処理中 ・・・・ \n",
      "✅ right フォルダ内の 3778 ファイルを処理中...\n",
      "  ├─ 3770 / 3778 ファイル処理中 ・ ・・ \n",
      "✅ on フォルダ内の 3845 ファイルを処理中...\n",
      "  ├─ 3840 / 3845 ファイル処理中 ・・・・ \n",
      "✅ off フォルダ内の 3745 ファイルを処理中...\n",
      "  ├─ 3740 / 3745 ファイル処理中 ・・ ・ \n",
      "✅ stop フォルダ内の 3872 ファイルを処理中...\n",
      "  ├─ 3870 / 3872 ファイル処理中 ・・・  \n",
      "✅ go フォルダ内の 3880 ファイルを処理中...\n",
      "  ├─ 3880 / 3880 ファイル処理中 ・・・・ \n",
      "✅ 処理完了！総ファイル数: 38546\n",
      "✅ 特徴量とラベルの保存が完了しました。\n",
      "特徴量の形状: (38546, 13) → ./data/features.npy\n",
      "ラベルの形状: (38546,) → ./data/labels.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "# データ保存先\n",
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "# ラベルのディクショナリ\n",
    "label_dict = {\"yes\": 0, \"no\": 1, \"up\": 2, \"down\": 3, \"left\": 4, \"right\": 5, \"on\": 6, \"off\": 7, \"stop\": 8, \"go\": 9}\n",
    "\n",
    "# 特徴量とラベルのリスト\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# 各フォルダ（ラベル）ごとに処理\n",
    "total_files = 0  # 全ファイル数カウント\n",
    "progress_symbols = [\"・\", \"・・\", \"・・・\", \"・・・・\"]  # インクリメント用記号\n",
    "\n",
    "for label, label_id in label_dict.items():\n",
    "    folder_path = os.path.join(DATA_DIR, label)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"⚠️ フォルダが見つかりません: {folder_path} → スキップ\")\n",
    "        continue  # フォルダが存在しない場合はスキップ\n",
    "\n",
    "    # フォルダ内の全てのwavファイルを取得\n",
    "    wav_files = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "\n",
    "    if len(wav_files) == 0:\n",
    "        print(f\"⚠️ {label} フォルダに音声ファイルがありません → スキップ\")\n",
    "        continue\n",
    "\n",
    "    print(f\"✅ {label} フォルダ内の {len(wav_files)} ファイルを処理中...\")\n",
    "\n",
    "    for i, wav_file in enumerate(wav_files):\n",
    "        try:\n",
    "            # 音声ファイルを読み込み\n",
    "            y, sr = librosa.load(wav_file, sr=None)\n",
    "            # MFCC特徴量を抽出\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            # 平均を取って1次元ベクトルに変換\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "            # 特徴量とラベルをリストに追加\n",
    "            features.append(mfcc_mean)\n",
    "            labels.append(label_id)\n",
    "            total_files += 1\n",
    "\n",
    "            # 進捗表示（10ファイルごとに更新）\n",
    "            if (i + 1) % 10 == 0:\n",
    "                symbol = progress_symbols[(i // 10) % len(progress_symbols)]\n",
    "                sys.stdout.write(f\"\\r  ├─ {i + 1} / {len(wav_files)} ファイル処理中 {symbol} \")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ エラー発生: {wav_file} ({str(e)})\")\n",
    "\n",
    "    print()  # 各フォルダの処理終了後、改行\n",
    "\n",
    "print(f\"✅ 処理完了！総ファイル数: {total_files}\")\n",
    "\n",
    "# リストをNumPy配列に変換\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 特徴量とラベルを保存\n",
    "features_path = os.path.join(DATA_DIR, \"features.npy\")\n",
    "labels_path = os.path.join(DATA_DIR, \"labels.npy\")\n",
    "\n",
    "np.save(features_path, features)\n",
    "np.save(labels_path, labels)\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"✅ 特徴量とラベルの保存が完了しました。\")\n",
    "print(f\"特徴量の形状: {features.shape} → {features_path}\")\n",
    "print(f\"ラベルの形状: {labels.shape} → {labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88f99dce-e536-4308-bfaa-be820c15eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベルデータの形状: (38546,)\n",
      "ラベルデータのユニーク数: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# ✅ 修正：labels.npy を正しくロードする\n",
    "labels_array = np.load(labels_path)\n",
    "\n",
    "# ロードしたデータの形状を確認\n",
    "print(f\"ラベルデータの形状: {labels_array.shape}\")\n",
    "print(f\"ラベルデータのユニーク数: {np.unique(labels_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574cbb7-9db1-4086-adc9-e95b16aa40d3",
   "metadata": {},
   "source": [
    "### データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71a51327-4b97-49a9-af59-ea709904f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修正後の特徴量データ: (38546, 13)\n",
      "修正後のラベルデータ: (38546,)\n",
      "訓練データ: (30836, 13), 検証データ: (3855, 13), テストデータ: (3855, 13)\n",
      "訓練ラベル: (30836,), 検証ラベル: (3855,), テストラベル: (3855,)\n",
      "訓練ラベルのユニーク値: [0 1 2 3 4 5 6 7 8 9]\n",
      "検証ラベルのユニーク値: [0 1 2 3 4 5 6 7 8 9]\n",
      "テストラベルのユニーク値: [0 1 2 3 4 5 6 7 8 9]\n",
      "✅ データセットの分割と保存が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = \"./data/\"\n",
    "\n",
    "# ✅ 保存した特徴量（MFCC）とラベルデータをロード\n",
    "npy_path = os.path.join(DATA_DIR, \"features.npy\")\n",
    "labels_path = os.path.join(DATA_DIR, \"labels.npy\")\n",
    "\n",
    "X = np.load(npy_path)  # 特徴量データ\n",
    "y = np.load(labels_path)  # ラベルデータ\n",
    "\n",
    "# ✅ 特徴量データとラベルデータのサイズを合わせる\n",
    "if len(y) > X.shape[0]:\n",
    "    y = y[:X.shape[0]]  # ラベルを特徴量データのサイズに切り詰める\n",
    "elif len(y) < X.shape[0]:\n",
    "    raise ValueError(f\"ラベルデータの数 ({len(y)}) が特徴量 ({X.shape[0]}) よりも少ないです。\")\n",
    "\n",
    "print(f\"修正後の特徴量データ: {X.shape}\")\n",
    "print(f\"修正後のラベルデータ: {y.shape}\")\n",
    "\n",
    "# ✅ データセットを分割（80% 訓練, 10% 検証, 10% テスト）\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# ✅ 分割結果を確認\n",
    "print(f\"訓練データ: {X_train.shape}, 検証データ: {X_val.shape}, テストデータ: {X_test.shape}\")\n",
    "print(f\"訓練ラベル: {y_train.shape}, 検証ラベル: {y_val.shape}, テストラベル: {y_test.shape}\")\n",
    "\n",
    "# ✅ 各データのラベル分布を確認\n",
    "print(f\"訓練ラベルのユニーク値: {np.unique(y_train)}\")\n",
    "print(f\"検証ラベルのユニーク値: {np.unique(y_val)}\")\n",
    "print(f\"テストラベルのユニーク値: {np.unique(y_test)}\")\n",
    "\n",
    "# ✅ 分割後のデータを保存\n",
    "np.save(os.path.join(DATA_DIR, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(DATA_DIR, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(DATA_DIR, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(DATA_DIR, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(DATA_DIR, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(DATA_DIR, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"✅ データセットの分割と保存が完了しました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
